{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SENTIMENTS = {\n",
    "        'POSITIVE': 1,\n",
    "        'NEGATIVE': -1,\n",
    "        'NEUTRAL': 0,\n",
    "        'UNKNOWN': 2\n",
    "    }\n",
    "\n",
    "CREDENTIALS = {\n",
    "    'host': 'ec2-50-17-207-16.compute-1.amazonaws.com',\n",
    "    'database': 'dcr3mmv32spva8',\n",
    "    'user': 'xobfxapscvkbir',\n",
    "    'port': '5432',\n",
    "    'pwd': '33487c61b69420cff89330da6fe2b82b280daabff756e82744a93cc4ddfc03f6',\n",
    "    'uri': 'postgres://xobfxapscvkbir:33487c61b69420cff89330da6fe2b82b280daabff756e82744a93cc4ddfc03f6@ec2-50-17-207-16.compute-1.amazonaws.com:5432/dcr3mmv32spva8',\n",
    "    'cli': 'heroku pg:psql postgresql-flat-49197 --app beepper'\n",
    "}\n",
    "\n",
    "COLUMNS = ['id','txt']\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        database=CREDENTIALS.get('database'),\n",
    "        user=CREDENTIALS.get('user'),\n",
    "        password=CREDENTIALS.get('pwd'),\n",
    "        host=CREDENTIALS.get('host'),\n",
    "        port=CREDENTIALS.get('port'),\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Connection to database failed\")\n",
    "\n",
    "curr = conn.cursor()\n",
    "curr.execute(\"SELECT id, txt_clean FROM hello_question\")\n",
    "res = curr.fetchall()\n",
    "\n",
    "curr.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(res,columns=COLUMNS).reset_index(drop=True)\n",
    "# data.to_csv('data/extract_23_02.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = {'médicaments': [1012, 994, 974, 919, 913, 801, 776, 770, 760, 733],\n",
    "'administratif': [1015, 1013, 1011, 1009, 986, 984, 981, 980, 979, 918],\n",
    "'pratique médicale': [1001,891,942,934,965,926,934,919,895,864], \n",
    "'diagnostique' : [989,987,985,964,957,951,950,937,903,872]}\n",
    "\n",
    "data['group'] = None\n",
    "for g in groups.items():\n",
    "    for i in g[1]:\n",
    "        data.ix[data.id==i, 'group'] = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015</td>\n",
       "      <td>Peut-on prescrire un arrêt de travail pour une...</td>\n",
       "      <td>administratif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                txt          group\n",
       "0  1015  Peut-on prescrire un arrêt de travail pour une...  administratif"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.ix[data.id==1015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class Matcher:\n",
    "    def __init__(self, num_match_returned=5):\n",
    "        self.num_match_returned = num_match_returned\n",
    "        self.stpwds = nltk.corpus.stopwords.words(\"french\")\n",
    "        self.vectorizer = None\n",
    "        self.dtm = None\n",
    "        self.questions_id = None\n",
    "        # rajouter des mots commes les, docteur, ...\n",
    "\n",
    "    def tokenize(self, content):\n",
    "        if content is None:\n",
    "            return None\n",
    "        else:\n",
    "            #remove http links\n",
    "            content = re.sub(r'http\\S+', '', content)\n",
    "            # remove formatting\n",
    "            content = re.sub(\"\\s+\", \" \", content)\n",
    "            # convert to lower case\n",
    "            content = content.lower()\n",
    "            # Remove accent\n",
    "            content = unidecode(content)\n",
    "            # remove punctuation (preserving intra-word dashes)\n",
    "            # content = \"\".join(letter for letter in content if letter not in punct)\n",
    "            punct = string.punctuation.replace(\"-\", \"\")\n",
    "            regex = re.compile('[%s]' % re.escape(punct))\n",
    "            content = regex.sub(' ', content)\n",
    "            content = re.sub(\"[^a-zA-Z]\", \" \", content)\n",
    "            # remove dashes attached to words but that are not intra-word\n",
    "            content = re.sub(\"[^[:alnum:]['-]\", \" \", content)\n",
    "            content = re.sub(\"[^[:alnum:][-']\", \" \", content)\n",
    "\n",
    "            # remove extra white space\n",
    "            content = re.sub(\" +\", \" \", content)\n",
    "            # remove leading and trailing white space\n",
    "            content = content.strip()\n",
    "            # tokenize\n",
    "            tokens = content.split(\" \")\n",
    "            # remove stopwords\n",
    "            tokens = [token for token in tokens if token not in self.stpwds and len(token) > 2]\n",
    "            return tokens\n",
    "        \n",
    "    def tokenize_dataset(self, data):\n",
    "        tokens = []\n",
    "        l = data.txt\n",
    "        if isinstance(l,str):\n",
    "            l = [l]\n",
    "        tokens = [self.tokenize(q) for q in l]\n",
    "        return tokens\n",
    "\n",
    "    def train(self, X):\n",
    "        tokens = self.tokenize_dataset(X)\n",
    "        voc = list(set([i for sublist in tokens if sublist is not None for i in sublist]))\n",
    "        join_tokens = [\" \".join(i) for i in tokens]\n",
    "        self.vectorizer = CountVectorizer(vocabulary=voc)\n",
    "        self.dtm = self.vectorizer.fit_transform(join_tokens)\n",
    "        return True\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.vectorizer is None:\n",
    "            self.train(X)\n",
    "        query_tokens = self.tokenize(query)\n",
    "        join_tokens = \" \".join(query_tokens)\n",
    "        transf = self.vectorizer.transform([join_tokens])\n",
    "        return transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Matcher()\n",
    "m.train(data)\n",
    "X = m.dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "5       True\n",
       "6       True\n",
       "7       True\n",
       "8       True\n",
       "9       True\n",
       "10      True\n",
       "11      True\n",
       "12      True\n",
       "13      True\n",
       "14      True\n",
       "15      True\n",
       "16      True\n",
       "17      True\n",
       "18      True\n",
       "19      True\n",
       "20      True\n",
       "21      True\n",
       "22      True\n",
       "23      True\n",
       "24      True\n",
       "25      True\n",
       "26     False\n",
       "27      True\n",
       "28      True\n",
       "29      True\n",
       "       ...  \n",
       "604     True\n",
       "605     True\n",
       "606     True\n",
       "607     True\n",
       "608    False\n",
       "609     True\n",
       "610     True\n",
       "611     True\n",
       "612     True\n",
       "613     True\n",
       "614     True\n",
       "615     True\n",
       "616     True\n",
       "617     True\n",
       "618     True\n",
       "619     True\n",
       "620     True\n",
       "621     True\n",
       "622     True\n",
       "623     True\n",
       "624     True\n",
       "625     True\n",
       "626    False\n",
       "627     True\n",
       "628     True\n",
       "629     True\n",
       "630     True\n",
       "631    False\n",
       "632     True\n",
       "633     True\n",
       "Name: group, dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data.group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1], dtype=int32),\n",
       " 0          administratif\n",
       " 26           médicaments\n",
       " 40         administratif\n",
       " 290          médicaments\n",
       " 309          médicaments\n",
       " 315          médicaments\n",
       " 325          médicaments\n",
       " 333    pratique médicale\n",
       " 351         diagnostique\n",
       " 353    pratique médicale\n",
       " 374        administratif\n",
       " 377    pratique médicale\n",
       " 382         diagnostique\n",
       " 384         diagnostique\n",
       " 385    pratique médicale\n",
       " 390        administratif\n",
       " 395        administratif\n",
       " 396    pratique médicale\n",
       " 397        administratif\n",
       " 400        administratif\n",
       " 401        administratif\n",
       " 402         diagnostique\n",
       " 403         diagnostique\n",
       " 404          médicaments\n",
       " 518        administratif\n",
       " 557          médicaments\n",
       " 582    pratique médicale\n",
       " 584          médicaments\n",
       " 586         diagnostique\n",
       " 587    pratique médicale\n",
       " 591         diagnostique\n",
       " 593         diagnostique\n",
       " 594          médicaments\n",
       " 596         diagnostique\n",
       " 597    pratique médicale\n",
       " 608          médicaments\n",
       " 626         diagnostique\n",
       " 631        administratif\n",
       " Name: group, dtype: object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "est = KMeans(n_clusters=4)\n",
    "est.fit(X)\n",
    "labels = est.labels_\n",
    "labels[~pd.isnull(data.group)], data.group[~pd.isnull(data.group)]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
